\documentclass[12pt]{article}
\usepackage[]{cite}
\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{amsmath, amsfonts,amssymb}
\usepackage{graphicx, epsfig}
\usepackage{subfig}
\usepackage{color}



\newcommand\argmin{\mathop{\arg\min}}
\newcommand{\T}{^{\text{\tiny\sffamily\upshape\mdseries T}}}
\newcommand{\hchi}{\hat{\boldsymbol{\chi}}}
\newcommand{\hphi}{\hat{\boldsymbol{\varphi}}}
\newcommand{\bchi}{\boldsymbol{\chi}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\Z}{\mathbf{Z}}
\newcommand{\hx}{\hat{x}}
\newcommand{\hX}{\hat{\X}}
\newcommand{\hy}{\hat{y}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\p}{p(\cdot)}
\newcommand{\q}{q(\cdot)}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}


\renewcommand{\baselinestretch}{1}


\newtheorem{Th}{Теорема}
\newtheorem{Def}{Определение}
\newenvironment{Proof} % имя окружения
    {\par\noindent{\bf Доказательство.}} % команды для \begin
    {\hfill$\scriptstyle\blacksquare$} % команды для \end
\newtheorem{Assumption}{Предположение}
\newtheorem{Corollary}{Следствие}

\textheight=24cm % высота текста
\textwidth=16cm % ширина текста
\oddsidemargin=0pt % отступ от левого края
\topmargin=-1.5cm % отступ от верхнего края
\parindent=24pt % абзацный отступ
\parskip=0pt % интервал между абзацами
\tolerance=2000 % терпимость к "жидким" строкам
\flushbottom % выравнивание высоты страниц

%\graphicspath{ {fig/} }



\begin{document}

\thispagestyle{empty}
\begin{center}
    \sc
        Министерство образования и науки Российской Федерации\\
        Московский физико-технический институт
        {\rm(государственный университет)}\\
        Факультет управления и прикладной математики\\
        Кафедра <<Интеллектуальные системы>>\\[35mm]
    \rm\large
        Самохина Алина Максимовна\\[10mm]
    \bf\Large
	Непрерывное представление времени\\ в задачах декодирования сигналов \\[10mm]
    \rm\normalsize
        010990 --- Интеллектуальный анализ данных\\[10mm]
    \sc
        Выпускная квалификационная работа магистра\\[10mm]
\end{center}
\hfill\parbox{80mm}{
    \begin{flushleft}
    \bf
        Научный руководитель:\\
    \rm
        д.~ф.-м.~н. Стрижов Вадим Викторович\\[5cm]
    \end{flushleft}
}
\begin{center}
    Москва\\
    2021
\end{center}


\newpage
\tableofcontents
\newpage

\begin{abstract}
1 вариант


    На сегодняшний день одной из важных задач на стыке биологии, медицины и компьютерных технологий является создание нейрокомпьютерных интерфейсов. Их алгоритмы решают задачу преобразования сигналов нейронов головного мозга в команды исполняющей системы. Это позволяет обеспечить управление внешними устройствами посредством импульсов мозга.
    
    При использовании доступных широкому пользователю устройств, считывающих активность мозга, зачастую возникают проблемы с качеством данных. Низкая частота сэмплирования, малое количество электродов и нерегулярность данных по сетке времени. Для решения данных проблем предлагается использовать непрерывное представление времени и пространства. 
    
    В данной работе рассматриваются подходы, позволяющие работать со временем как с непрерывной переменной. Показано, что применение алгоритмов на основе нейронных обыкновенных дифференциальных уравнений позволяет представить сигнал как непрерывный по времени. Также рассматриваются различные возможности применения данных подходов в реальных задачах.
    
2 вариант

    В задачах декодирования сигнала данные представляются как многомерные временные ряды. При решении задач используется дискретное представление времени. Однако недавние работы по нейронныи обыкновенным дифференциальным уравнениям иллюстрируют возможность работать с рекуррентными нейронными сетями, как с дифференциальными уравнениями, а скрытое состояние представлять непрерывной функцией.
    
    В данной работе рассматривается возможность представления самого сигнала как непрерывной по времени функции. Исследуются возможности практического применения данного подхода: для изменения частоты семплирования сигнала, обработки нерегулярных сигналов или сигналов с пропущенными значчениями. Данные применения являются актуальными для сигналов с различных носимых устройств: акселерометров, пульсометров, устройств для снятия сигналов головного мозга.
    
    Основным результатом является алгоритм, позволяющий работать с сигналом как с непрерывным по времени и и являющийся базой для дальнейших исследований на тему непрерывности сигнала по пространственной компоненте.

  \bigskip
  \textbf{Ключевые слова}: \emph{ЭЭГ, нейронные ОДУ, управляемые ДУ, полиномы Лежандра
  }
\end{abstract}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Введение}
\addcontentsline{toc}{section}{\protect\numberline{}Введение}


%[1] обзор	
%[1] развернутая постановка задачи	
%[4] теоретическая часть //part	
%[2] код и эксперимент	//part
%[1] анализ ошибки (текст и графики) //part	
%[1] готовый текст работы	
%[1] подготовлено к подаче	
%[1] готов доклад


\paragraph{Актуальность темы.}
Магистерская работа посвящена задаче непрерывного представления времени в задачах декодирования сигналов. 

Фокусом работы является исследование того, какие возможности дает непрерывное пердставление сигнала по времени, а также ответ на вопрос, можем ли также рассматривать непрерывность сигнала в пространстве. 

Пример повседневных задач декодирования сигнала ~--- работа с сигналами с носимых устройств. Акселерометры, пульсометры, устройства для снятия ЭЭГ являются носимыми устройствами. Они должны быть доступны для обычных пользователей, в связи с чем должны иметь невысокую себестоимость. Результатом низкой стоимости устройств являются: низкая частота сэмплирования, малое количество датчиков, периодическая потеря контакта с устройством во время передачи данных. Таким образом, на выходе с устройства мы получаем зашумленный сигнал с нерегулярным шагом по временной сетке. 

Предполагается, что непрерывность сигнала по времени позволит решить вышеназванные проблемы с сигналами.

В последние несколько лет появилось большое количество работ по теме нейронных обыкновенных дифференциальных уравнений (нейронных ОДУ) \cite{a lot of papers}

Из существующих подходов, рассматривающих непрерывные сигналы: %cite another paper's related work


% SyperRES intro
Большинство подходов опираются на статью \cite{neural_ode}. Авторы предлагают рассматривать ResidualBlock \cite{ResNet} как обыкновенное дифференциальное уравнение, исходя из синтаксической схожести скрытого слоя с формулой Эйлера для численного интегрирования ОДУ. Однако входные данные для этих сетей не являются временными рядами и непрерывность рассматривается в контексте непрерывности скрытого состояния RNN\ cite{RNN}.
%Так как синтаксической схожести недостаточно для утверждения о том, что нейронная сеть может представлять собой решение дифференциального уравнения, авторы работы \cite{contindepth} показали, что несмотря на то, что ResidualBlock не вляется аналогом метода Эйлера, конструкция NeuralODE, рассматривающая схемы интегрирования методом Рунге-Кутты четвертого порядка может считаться численным интегратором по всем свойствам сходимости.
Следующим шагом в NeuralODE стали работы \cite{cde}, \cite{latentode}, \cite{ode2vae}, которые, в свою очередь, рассматривают различные варианты работы с временными рядами в контексте нейронных ОДУ. Однако ни один из этих подходов не позволяет получить непрерывное представление исходного сигнала. 
%Для дальнейших исследований также было бы интересно рассмотреть интеграцию нейронных уравнений с байесовскими методами \cite{latentode}, \cite{odegrubayes}, \cite{ode2vae}, где с помощью нейронных ОДУ строится непрерывное по времени латентное пространство исходного сигнала.
В основу данного исследования легли работы \cite{cde}, рассматривающая возможность применения нейронных ОДУ к временным рядам с нерегулярной сеткой по времени, и работа \cite{lmu}, позволяющая получить непрерывное представление сигнала в памяти LSTM \cite{LSTM} с использованием полиномов Лежандра \cite{legendre_polynom}. Таки образом, результатом данной работы будет являться непрерывная в глубину нейронная сеть, позволяющая представить сигнал непрерывным по времени.

Большинство рассмотренных работа рассматривают в качестве данных для тестирования моделей toy datasets и MNIST\cite{mnist}. Мы же обратимся к реальным данным.

В последнее время большое количество работ посвящено методам считывания мозговой активности и декодирования информации \cite{Hu2018,Song2017,Loza2017,Eliseyev2016,Gaglianese2016,Bundy2016,Morishita2014}. Основным приложением данных методов являются нейрокомпьютерные интерфейсы.

Нейрокомпьютерный интерфейс (НКИ) ~--- технология, позволяющая человеку взаимодейстовать с компьютером с помощью анализа данных о мозговой активности. 
В первую очередь НКИ разрабатывались для пациентов с ограниченными возможностями и использовались для коммуникации пациентов с различными формами паралича и для реабилитации моторной функции после инсультов и спинальных травм \cite{chaudhary2020neuropsychological}.

В связи с большим интересом к НКИ как для медицинских целей \cite{Hu2018,Song2017,Loza2017,Eliseyev2016,Gaglianese2016,Bundy2016,Morishita2014}, так и для широкого пользователя \cite{KaplanShishkin}, основными сигналами, рассматриваемыми в работе, являются сигналы головного мозга: электрокортикограммы \cite{ECOG} и электроэнцефалограммы  \cite{EEG}.

На сегодняшний день существует множество подходов к использованию НКИ, основанных на неинвазивных электродах, для здоровых людей \cite{NER_2015}. Кроме того, НКИ могут быть использованы в рекреационных целях, например, в играх \cite{Recreational_Applications}, \cite{Kaplan_Shishkin_games}.


Для построения НКИ используются различные виды биосигналов как требующих операции для имплантации электродов \cite{collinger2013high}, так и неинвазивных:  fNIRS \cite{nazeer2020enhancing}, фМРТ \cite{yoo2004brain}, ЭЭГ. Нейроинтерфейсы на основе электроэнцефалограммы (ЭЭГ) остаются на данный момент наиболее популярными за счет лёгкой настройки, низкой стоимости и высокого временного разрешения метода. 
    
Существует несколько разновидностей нейрокомпьютерных интерфесов: пассивные, активные и реактивные.

Пассивные НКИ ~--- вид нейроинтерфейсов, в которых в фоновом режиме считываются реакции мозга человека не в контексте осознанного выполнения задачи нейроуправления. Полученные данные, которые могут говорить об уровне утомления и когнитивной нагрузке на фоне выполнении задачи, могут использоваться для обратной связи и облегчения работы пользователя \cite{andreessen2020toward}.


Так называемые "активные" \ НКИ распознают изменение активности мозга при выполнении различных ментальных действий \cite{zander2010enhancing}. Примером является нейроинтерфейс, распознающий изменения ритмической активности ЭЭГ при расслаблении и ментальной концентрации \cite{chen2009model}. 

В активных нейроинтерфейсах на основе анализа ритмической активности ЭЭГ пользователи могут достигать  точности выбора двух или трех команд около 70\%. Достижение более высокой точности осложнено сложностью ментальной задачи для неподготовленного человека и необходимостью обучения пользователя ее правильному выполнению.
    
    
    
Реактивные нейроинтерфейсы работают за счет выяления реакций мозга на специфическую стимуляцию. Пользователь привлекает свое внимание к одному из нескольких стимулов, которые вызывают реакции ЭЭГ. Стимулы могут иметь различную модальность (к примеру, слуховую и тактильную), но самые надежные НКИ создаются на основе зрительных стимулов разных типов, которые вызывают различные ответы мозга.
    
Самый популярный вид реактивных НКИ ~--- НКИ на основе вызванного потенциала P300. В данном типе нейроинтерфейса управление совершается за счет привлечения внимания к разнесенным во времени стимулам. При активации стимула, на который пользователь хочет отреагировать, в окружении стимулов, которые ему безразличны, в центральных отведениях регистрируется потенциал, связанный с событием с латентностью (задержкой во времени) пика около 300 мс после стимула \cite{polich2007updating}. Нейроинтерфейсы на основе P300 имеют высокую скорость передачи информации за счет высокой точности классификации команд и потенциально большое их количество. На основе этой технологии также можно создание систем набора текста. Преимущество НКИ-Р300 заключается в меньшей чувствительности к модальности стимула - по сути, один и тот же интерфейс можно использовать со стимулами любых форм и размеров, при условии, что они достаточно легко различимы. Это позволяет создать интерфейс не только полезный пациентам, но и интересный для здоровых пользователей. 
    








\paragraph{Цель работы.}

Целью работы является построение непрерывного представления сигнала по времени. Основные практические задачи, которые предполагается возможным решить с помощью рассматриваемого подхода:
\begin{itemize}
    \item изменение частоты семплирования
    \item работа с временными рядами с нерегулярной сеткой по времени или пропущенными значениями
\end{itemize}


В дальнейшем используемые подходы могут быть расширены и на непрерывное представление пространства.


\paragraph{Методы исследования.}



В работе рассматривается применение алгоритмов на основе нейронных дифференциальных уравнений к двум прикладным задачам: предсказание координаты конечности по данным с инвазивных электродов (электрокортикограмма) \cite{neurotycho}, определение объекта внимания пользователя по данным с неинвазивных электродов на основе парадигмы P300 \cite{sth about P300}.



\paragraph{Основные положения, выносимые на защиту.}
\begin{enumerate}
  \item Модель, позволяющая оперировать сигналами как непрерывными по времени
  \item Возможности для практического применения данного подхода
  \item Теорема о сходимости
  \item Теорема об универсальном аппроксиматоре
  \item Экспериментальное исследование разработанных алгоритмов
  %содержащее их сравнение с аналогами.
\end{enumerate}

\paragraph{Научная новизна.}

\paragraph{Теоретическая значимость.}

\paragraph{Практическая значимость.}


\paragraph{Степень достоверности и апробация работы.}
Достоверность результатов подтверждена экспериментальной проверкой полученных методов на реальных задачах.
%, публикациями результатов исследования в рецензируемых научных изданиях, в том числе рекомендованными ВАК. 
%Некоторые результаты работы докладывались и обсуждались на следующих научных конференциях
%\begin{itemize}
%  \item 13-я Международная конференция «Интеллектуализация обработки информации», 2020 г.\cite{IDP2020};
%  \item 63-я Всероссийская научная конференция МФТИ, 2020 г. \cite{mipt2020};
%\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section*{Обозначения}
\addcontentsline{toc}{section}{\protect\numberline{}Обозначения}

\begin{itemize}
    \item $E$ ~--- количество электродов в ЭЭГ

\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Постановка задачи}

Suppose for simplicity that we have a fully-observed but potentially irregularly sampled time series $\mathbf{x}=\left(\left(t_{0}, x_{0}\right),\left(t_{1}, x_{1}\right), \ldots,\left(t_{n}, x_{n}\right)\right)$, with each $t_{i} \in \mathbb{R}$ the timestamp of the observation $x_{i} \in \mathbb{R}^{v}$
and $t_{0}<\cdots<t_{n}$. (We will consider partially-observed data later.)
\cite{neural_ode}, \cite{cde}. \cite{dda_ts}
Let $X:\left[t_{0}, t_{n}\right] \rightarrow \mathbb{R}^{v+1}$ be the natural cubic spline with knots at $t_{0}, \ldots, t_{n}$ such that $X_{t_{i}}=\left(x_{i}, t_{i}\right)$. As $\mathrm{x}$ is often assumed to be a discretisation of an underlying process, observed only through $\mathrm{x}$, then $X$ is an approximation to this underlying process. Natural cubic splines have essentially the minimum regularity for handling certain edge cases; see Appendix $\mathbb{A}$ for the technical details.

Let $f_{\theta}: \mathbb{R}^{w} \rightarrow \mathbb{R}^{w \times(v+1)}$ be any neural network model depending on parameters $\theta .$ The value $w$ is a hyperparameter describing the size of the hidden state. Let $\zeta_{\theta}: \mathbb{R}^{v+1} \rightarrow \mathbb{R}^{w}$ be any neural network model depending on parameters $\theta$.
Then we define the neural controlled differential equation model as the solution of the CDE
$$
z_{t}=z_{t_{0}}+\int_{t_{0}}^{t} f_{\theta}\left(z_{s}\right) \mathrm{d} X_{s} \quad \text { for } t \in\left(t_{0}, t_{n}\right]
$$


%с разбиением на тренировочную $D_{train}$ и тестовую $D_{test}$ подвыборки. 

Основная задача работы ~--- 



В качестве критерия рассматривается :
$$ L(\theta|\X) =  $$

И решается задача оптимизации
$$\hat{\theta} = \arg\max_{\theta} L(\theta, \X)$$




Для вычислительных экспериментов были использованы несколько датасетов из различных источников. Подробное описание приводится в разделе 4.1.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Обзор существующих алгоритмов }
\subsection{1}

\subsection{2}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Предлагаемый метод}
Для решения задачи предлагается использовать

\subsection{Анализ недостатков существующих алгоритмов}
\subsubsection{1}

\subsubsection{2}

\subsubsection{3}

\subsection{Предлагаемый подход}

\subsection{Оценка качества}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Вычислительный эксперимент}
\begin{enumerate}
    \item 1
    \item 2
    \item 3
    \item 4
\end{enumerate}

\subsection{Экспериментальные данные}
\subsubsection{Наборы данных}
Вычислительные эксперименты проводятся на т

\subsection{Результаты}
\subsubsection{Базовый эксперимент}

В базовом эксперименте был использован датасет описанный в пункте 4.1.1.


В качестве базового алгоритма была взята модель 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section*{Заключение}
\addcontentsline{toc}{section}{\protect\numberline{}Заключение}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\addcontentsline{toc}{section}{\protect\numberline{}Список литературы}
\bibliographystyle{ugost2008}
\bibliography{citations}

\end{document} 